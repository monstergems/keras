{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_MLP(n_nodes=200,activation_func=\"relu\",learning_rate=0.01,input_Shape=[28,28],output_shape=10):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Flatten(input_shape=(input_Shape[0],input_Shape[1])))\n",
    "    model.add(keras.layers.Dense(n_nodes, activation=activation_func))\n",
    "    model.add(keras.layers.Dense(output_shape, activation=\"softmax\"))\n",
    "    optimizer = keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "    model.compile(loss=\"sparse_categorical_crossentropy\",optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "def build_test_model():\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "    model.add(keras.layers.Dense(300, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(100, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "    optimizer_sgd=keras.optimizers.SGD(learning_rate=0.01)\n",
    "    model.compile(loss=\"sparse_categorical_crossentropy\",optimizer=optimizer_sgd, metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "fashion_mnist=keras.datasets.fashion_mnist\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()\n",
    "print(X_train_full[0])\n",
    "print(X_train_full[0]/255.0)\n",
    "\n",
    "x_train,x_val,y_train,y_val=sklearn.model_selection.train_test_split(X_train_full/255.0,y_train_full,test_size=0.1,random_state=42)\n",
    "print(x_train.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search 1\n",
      "Epoch 1/5\n",
      "1688/1688 [==============================] - 14s 7ms/step - loss: 1.0515 - accuracy: 0.6982 - val_loss: 0.7235 - val_accuracy: 0.7567\n",
      "Epoch 2/5\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.6501 - accuracy: 0.7762 - val_loss: 0.6090 - val_accuracy: 0.7845\n",
      "Epoch 3/5\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.5701 - accuracy: 0.8028 - val_loss: 0.5527 - val_accuracy: 0.8038\n",
      "Epoch 4/5\n",
      "1688/1688 [==============================] - 12s 7ms/step - loss: 0.5279 - accuracy: 0.8162 - val_loss: 0.5158 - val_accuracy: 0.8172\n",
      "Epoch 5/5\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.5023 - accuracy: 0.8249 - val_loss: 0.4959 - val_accuracy: 0.8245\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 1.2219 - accuracy: 0.7409\n",
      "search 2\n",
      "Epoch 1/5\n",
      "1688/1688 [==============================] - 11s 6ms/step - loss: 1.2022 - accuracy: 0.6804 - val_loss: 0.8256 - val_accuracy: 0.7417\n",
      "Epoch 2/5\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.7173 - accuracy: 0.7676 - val_loss: 0.6579 - val_accuracy: 0.7772\n",
      "Epoch 3/5\n",
      "1688/1688 [==============================] - 8s 5ms/step - loss: 0.6125 - accuracy: 0.7933 - val_loss: 0.5898 - val_accuracy: 0.7947\n",
      "Epoch 4/5\n",
      "1688/1688 [==============================] - 11s 6ms/step - loss: 0.5592 - accuracy: 0.8099 - val_loss: 0.5466 - val_accuracy: 0.8097\n",
      "Epoch 5/5\n",
      "1688/1688 [==============================] - 16s 10ms/step - loss: 0.5258 - accuracy: 0.8197 - val_loss: 0.5184 - val_accuracy: 0.8200\n",
      "313/313 [==============================] - 4s 9ms/step - loss: 0.8328 - accuracy: 0.7511\n",
      "search 3\n",
      "Epoch 1/5\n",
      "1688/1688 [==============================] - 22s 9ms/step - loss: 1.2846 - accuracy: 0.6613 - val_loss: 0.8785 - val_accuracy: 0.7363\n",
      "Epoch 2/5\n",
      "1688/1688 [==============================] - 12s 7ms/step - loss: 0.7633 - accuracy: 0.7558 - val_loss: 0.6970 - val_accuracy: 0.7628\n",
      "Epoch 3/5\n",
      "1688/1688 [==============================] - 11s 7ms/step - loss: 0.6527 - accuracy: 0.7767 - val_loss: 0.6264 - val_accuracy: 0.7825\n",
      "Epoch 4/5\n",
      "1688/1688 [==============================] - 11s 6ms/step - loss: 0.5974 - accuracy: 0.7935 - val_loss: 0.5833 - val_accuracy: 0.7960\n",
      "Epoch 5/5\n",
      "1688/1688 [==============================] - 11s 6ms/step - loss: 0.5615 - accuracy: 0.8050 - val_loss: 0.5524 - val_accuracy: 0.8045\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 1.0298 - accuracy: 0.7281\n",
      "search 4\n",
      "Epoch 1/5\n",
      "1688/1688 [==============================] - 14s 8ms/step - loss: 1.7066 - accuracy: 0.5071 - val_loss: 1.3640 - val_accuracy: 0.6457\n",
      "Epoch 2/5\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 1.1790 - accuracy: 0.6749 - val_loss: 1.0653 - val_accuracy: 0.6803\n",
      "Epoch 3/5\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.9734 - accuracy: 0.7035 - val_loss: 0.9267 - val_accuracy: 0.7033\n",
      "Epoch 4/5\n",
      "1688/1688 [==============================] - 13s 7ms/step - loss: 0.8678 - accuracy: 0.7281 - val_loss: 0.8452 - val_accuracy: 0.7282\n",
      "Epoch 5/5\n",
      "1688/1688 [==============================] - 15s 9ms/step - loss: 0.8015 - accuracy: 0.7464 - val_loss: 0.7910 - val_accuracy: 0.7468\n",
      "313/313 [==============================] - 6s 13ms/step - loss: 62.1449 - accuracy: 0.7236\n",
      "search 5\n",
      "Epoch 1/5\n",
      "1688/1688 [==============================] - 23s 10ms/step - loss: 0.6497 - accuracy: 0.7808 - val_loss: 0.5620 - val_accuracy: 0.7942\n",
      "Epoch 2/5\n",
      "1688/1688 [==============================] - 14s 8ms/step - loss: 0.4773 - accuracy: 0.8343 - val_loss: 0.5153 - val_accuracy: 0.8130\n",
      "Epoch 3/5\n",
      "1688/1688 [==============================] - 14s 8ms/step - loss: 0.4376 - accuracy: 0.8469 - val_loss: 0.4679 - val_accuracy: 0.8282\n",
      "Epoch 4/5\n",
      "1688/1688 [==============================] - 11s 6ms/step - loss: 0.4129 - accuracy: 0.8558 - val_loss: 0.4337 - val_accuracy: 0.8470\n",
      "Epoch 5/5\n",
      "1688/1688 [==============================] - 12s 7ms/step - loss: 0.3941 - accuracy: 0.8623 - val_loss: 0.4095 - val_accuracy: 0.8528\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 76.8533 - accuracy: 0.8114\n",
      "[[193, 'sigmoid', 0.01841618060734781], [57, 'sigmoid', 0.016954943542284957], [122, 'sigmoid', 0.011419403577876547], [99, 'relu', 0.0005212944909869379], [94, 'relu', 0.021151556840330935]]\n",
      "[1.2218654155731201, 0.8327875733375549, 1.0297664403915405, 62.14493179321289, 76.85331726074219]\n"
     ]
    }
   ],
   "source": [
    "#hyper parameter tuning through random search\n",
    "tests=5\n",
    "n_nodes=np.arange(199)+1\n",
    "activation_functions=[\"elu\",\"relu\",\"sigmoid\"]\n",
    "learning_rates=[0.0003,0.03]\n",
    "used_parameters=[]\n",
    "gained_scores=[]\n",
    "early_stoping=keras.callbacks.EarlyStopping(patience=5)\n",
    "for i in range(tests):\n",
    "    print(\"search \"+str(i+1))\n",
    "    nodes=n_nodes[random.randint(0,len(n_nodes)-1)]\n",
    "    activation=activation_functions[random.randint(0,len(activation_functions)-1)]\n",
    "    learning_rate=random.uniform(learning_rates[0],learning_rates[1])\n",
    "    used_parameters.append([nodes,activation,learning_rate])\n",
    "\n",
    "    model=build_MLP(n_nodes=nodes,activation_func=activation,learning_rate=learning_rate)\n",
    "    #model=build_test_model()\n",
    "    history = model.fit(x_train, y_train, epochs=5,validation_data=(x_val, y_val),callbacks=[early_stoping])\n",
    "    gained_scores.append(model.evaluate(X_test, y_test)[1])\n",
    "print(used_parameters)\n",
    "print(gained_scores)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
